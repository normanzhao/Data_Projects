{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_players = pd.read_pickle(\"all_players.pkl\")\n",
    "reg_players = pd.read_pickle(\"reg_players.pkl\")\n",
    "hof_players = pd.read_pickle(\"hof_players.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Helper function to convert height from a readable format to inches\n",
    "def readable_to_inches(x):\n",
    "    if x == 0:\n",
    "        return\n",
    "    inches = str(x).split('-')\n",
    "    return (int(inches[0])*12)+int(inches[1])\n",
    "\n",
    "all_players[\"Ht\"] = all_players[\"Ht\"].apply(readable_to_inches)\n",
    "reg_players[\"Ht\"] = reg_players[\"Ht\"].apply(readable_to_inches)\n",
    "hof_players[\"Ht\"] = hof_players[\"Ht\"].apply(readable_to_inches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up the data a bit by dropping positions, birth dates, colleges and their player page URL. I'll also fill in NaNs with 0s and shift the player name to be the index so all the columns will be quantitative and have a value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_players.drop([\"Pos\",\"Birth Date\",\"Colleges\",\"URL\"],axis=1,inplace=True)\n",
    "reg_players.drop([\"Pos\",\"Birth Date\",\"Colleges\",\"URL\"],axis=1,inplace=True)\n",
    "hof_players.drop([\"Pos\",\"Birth Date\",\"Colleges\",\"URL\"],axis=1,inplace=True)\n",
    "all_players.set_index('Player',inplace=True)\n",
    "reg_players.set_index('Player',inplace=True)\n",
    "hof_players.set_index('Player',inplace=True)\n",
    "all_players.fillna(0,inplace=True)\n",
    "reg_players.fillna(0,inplace=True)\n",
    "hof_players.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the dataset to get the average, standard deviation and max across all players. This is useful information to see the average of the career averages of all the players who've ever played in the NBA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4580\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Ht</th>\n",
       "      <th>Wt</th>\n",
       "      <th>Years of Service</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>2P</th>\n",
       "      <th>2PA</th>\n",
       "      <th>2P%</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>FT</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>Teams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1985.291921</td>\n",
       "      <td>1989.475983</td>\n",
       "      <td>78.002620</td>\n",
       "      <td>208.621616</td>\n",
       "      <td>4.184061</td>\n",
       "      <td>275.614629</td>\n",
       "      <td>91.408079</td>\n",
       "      <td>15.439913</td>\n",
       "      <td>2.468013</td>\n",
       "      <td>5.839170</td>\n",
       "      <td>0.405636</td>\n",
       "      <td>0.211026</td>\n",
       "      <td>0.643144</td>\n",
       "      <td>0.152528</td>\n",
       "      <td>1.708472</td>\n",
       "      <td>3.691856</td>\n",
       "      <td>0.334530</td>\n",
       "      <td>0.338043</td>\n",
       "      <td>1.303712</td>\n",
       "      <td>1.816769</td>\n",
       "      <td>0.666403</td>\n",
       "      <td>0.737511</td>\n",
       "      <td>1.617751</td>\n",
       "      <td>2.878843</td>\n",
       "      <td>1.424956</td>\n",
       "      <td>0.415284</td>\n",
       "      <td>0.239345</td>\n",
       "      <td>0.854869</td>\n",
       "      <td>1.815022</td>\n",
       "      <td>6.446638</td>\n",
       "      <td>2.681659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21.073436</td>\n",
       "      <td>21.944760</td>\n",
       "      <td>3.820211</td>\n",
       "      <td>27.291328</td>\n",
       "      <td>4.498959</td>\n",
       "      <td>310.838927</td>\n",
       "      <td>201.040494</td>\n",
       "      <td>9.700809</td>\n",
       "      <td>1.810298</td>\n",
       "      <td>3.873235</td>\n",
       "      <td>0.109270</td>\n",
       "      <td>0.402833</td>\n",
       "      <td>1.105978</td>\n",
       "      <td>0.171514</td>\n",
       "      <td>1.794362</td>\n",
       "      <td>3.706936</td>\n",
       "      <td>0.213343</td>\n",
       "      <td>0.214088</td>\n",
       "      <td>1.117810</td>\n",
       "      <td>1.441973</td>\n",
       "      <td>0.196767</td>\n",
       "      <td>0.766755</td>\n",
       "      <td>1.605284</td>\n",
       "      <td>2.380207</td>\n",
       "      <td>1.364652</td>\n",
       "      <td>0.428248</td>\n",
       "      <td>0.365912</td>\n",
       "      <td>0.773852</td>\n",
       "      <td>0.845626</td>\n",
       "      <td>4.748298</td>\n",
       "      <td>1.943505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2018.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1611.000000</td>\n",
       "      <td>1471.000000</td>\n",
       "      <td>45.800000</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>23.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>21.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>30.100000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             From           To         Ht          Wt  Years of Service  \\\n",
       "mean  1985.291921  1989.475983  78.002620  208.621616          4.184061   \n",
       "std     21.073436    21.944760   3.820211   27.291328          4.498959   \n",
       "max   2018.000000  2018.000000  91.000000  360.000000         22.000000   \n",
       "\n",
       "                G           GS         MP         FG        FGA       FG%  \\\n",
       "mean   275.614629    91.408079  15.439913   2.468013   5.839170  0.405636   \n",
       "std    310.838927   201.040494   9.700809   1.810298   3.873235  0.109270   \n",
       "max   1611.000000  1471.000000  45.800000  12.100000  23.800000  1.000000   \n",
       "\n",
       "            3P       3PA       3P%         2P        2PA       2P%      eFG%  \\\n",
       "mean  0.211026  0.643144  0.152528   1.708472   3.691856  0.334530  0.338043   \n",
       "std   0.402833  1.105978  0.171514   1.794362   3.706936  0.213343  0.214088   \n",
       "max   3.400000  7.800000  1.000000  10.800000  21.300000  1.000000  1.500000   \n",
       "\n",
       "            FT        FTA       FT%       ORB        DRB        TRB  \\\n",
       "mean  1.303712   1.816769  0.666403  0.737511   1.617751   2.878843   \n",
       "std   1.117810   1.441973  0.196767  0.766755   1.605284   2.380207   \n",
       "max   7.800000  11.400000  1.000000  5.100000  10.400000  22.900000   \n",
       "\n",
       "            AST       STL       BLK       TOV        PF        PTS      Teams  \n",
       "mean   1.424956  0.415284  0.239345  0.854869  1.815022   6.446638   2.681659  \n",
       "std    1.364652  0.428248  0.365912  0.773852  0.845626   4.748298   1.943505  \n",
       "max   11.200000  2.700000  3.500000  4.400000  5.000000  30.100000  13.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(all_players)\n",
    "all_players.describe().loc[['mean','std','max']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the same stats, but this time for separating between HOF and non-HOF players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4440\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Ht</th>\n",
       "      <th>Wt</th>\n",
       "      <th>Years of Service</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>2P</th>\n",
       "      <th>2PA</th>\n",
       "      <th>2P%</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>FT</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>Teams</th>\n",
       "      <th>AllStars</th>\n",
       "      <th>MVPs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1985.810135</td>\n",
       "      <td>1989.769144</td>\n",
       "      <td>77.998198</td>\n",
       "      <td>208.647748</td>\n",
       "      <td>3.959009</td>\n",
       "      <td>257.868468</td>\n",
       "      <td>85.361036</td>\n",
       "      <td>14.913333</td>\n",
       "      <td>2.344167</td>\n",
       "      <td>5.584054</td>\n",
       "      <td>0.404084</td>\n",
       "      <td>0.212185</td>\n",
       "      <td>0.646959</td>\n",
       "      <td>0.153380</td>\n",
       "      <td>1.645878</td>\n",
       "      <td>3.573536</td>\n",
       "      <td>0.336556</td>\n",
       "      <td>0.340149</td>\n",
       "      <td>1.218784</td>\n",
       "      <td>1.707860</td>\n",
       "      <td>0.663525</td>\n",
       "      <td>0.721036</td>\n",
       "      <td>1.571351</td>\n",
       "      <td>2.737432</td>\n",
       "      <td>1.356532</td>\n",
       "      <td>0.404752</td>\n",
       "      <td>0.230248</td>\n",
       "      <td>0.835450</td>\n",
       "      <td>1.780608</td>\n",
       "      <td>6.115383</td>\n",
       "      <td>2.675901</td>\n",
       "      <td>0.228153</td>\n",
       "      <td>0.003153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21.041313</td>\n",
       "      <td>22.024369</td>\n",
       "      <td>3.815820</td>\n",
       "      <td>27.296752</td>\n",
       "      <td>4.324955</td>\n",
       "      <td>293.754773</td>\n",
       "      <td>186.448140</td>\n",
       "      <td>9.311707</td>\n",
       "      <td>1.653524</td>\n",
       "      <td>3.577950</td>\n",
       "      <td>0.110185</td>\n",
       "      <td>0.403022</td>\n",
       "      <td>1.107211</td>\n",
       "      <td>0.172035</td>\n",
       "      <td>1.664794</td>\n",
       "      <td>3.463517</td>\n",
       "      <td>0.211788</td>\n",
       "      <td>0.212505</td>\n",
       "      <td>0.991077</td>\n",
       "      <td>1.280241</td>\n",
       "      <td>0.198728</td>\n",
       "      <td>0.739985</td>\n",
       "      <td>1.522384</td>\n",
       "      <td>2.158248</td>\n",
       "      <td>1.279941</td>\n",
       "      <td>0.412261</td>\n",
       "      <td>0.343900</td>\n",
       "      <td>0.738876</td>\n",
       "      <td>0.829725</td>\n",
       "      <td>4.327541</td>\n",
       "      <td>1.951462</td>\n",
       "      <td>1.021936</td>\n",
       "      <td>0.082148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2018.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1471.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>13.400000</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>27.200000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             From           To         Ht          Wt  Years of Service  \\\n",
       "mean  1985.810135  1989.769144  77.998198  208.647748          3.959009   \n",
       "std     21.041313    22.024369   3.815820   27.296752          4.324955   \n",
       "max   2018.000000  2018.000000  91.000000  360.000000         22.000000   \n",
       "\n",
       "                G           GS         MP        FG        FGA       FG%  \\\n",
       "mean   257.868468    85.361036  14.913333  2.344167   5.584054  0.404084   \n",
       "std    293.754773   186.448140   9.311707  1.653524   3.577950  0.110185   \n",
       "max   1471.000000  1440.000000  39.000000  9.900000  19.600000  1.000000   \n",
       "\n",
       "            3P       3PA       3P%        2P        2PA       2P%      eFG%  \\\n",
       "mean  0.212185  0.646959  0.153380  1.645878   3.573536  0.336556  0.340149   \n",
       "std   0.403022  1.107211  0.172035  1.664794   3.463517  0.211788  0.212505   \n",
       "max   3.400000  7.800000  1.000000  8.500000  17.000000  1.000000  1.500000   \n",
       "\n",
       "            FT       FTA       FT%       ORB       DRB        TRB       AST  \\\n",
       "mean  1.218784  1.707860  0.663525  0.721036  1.571351   2.737432  1.356532   \n",
       "std   0.991077  1.280241  0.198728  0.739985  1.522384   2.158248  1.279941   \n",
       "max   7.100000  9.100000  1.000000  4.700000  9.100000  13.400000  9.800000   \n",
       "\n",
       "           STL       BLK       TOV        PF        PTS      Teams   AllStars  \\\n",
       "mean  0.404752  0.230248  0.835450  1.780608   6.115383   2.675901   0.228153   \n",
       "std   0.412261  0.343900  0.738876  0.829725   4.327541   1.951462   1.021936   \n",
       "max   2.700000  3.500000  4.000000  5.000000  27.200000  13.000000  18.000000   \n",
       "\n",
       "          MVPs  \n",
       "mean  0.003153  \n",
       "std   0.082148  \n",
       "max   4.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(reg_players)\n",
    "reg_players.describe().loc[['mean','std','max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Ht</th>\n",
       "      <th>Wt</th>\n",
       "      <th>Years of Service</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>2P</th>\n",
       "      <th>2PA</th>\n",
       "      <th>2P%</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>FT</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>Teams</th>\n",
       "      <th>AllStars</th>\n",
       "      <th>MVPs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1968.857143</td>\n",
       "      <td>1980.178571</td>\n",
       "      <td>78.142857</td>\n",
       "      <td>207.792857</td>\n",
       "      <td>11.321429</td>\n",
       "      <td>838.421429</td>\n",
       "      <td>283.185714</td>\n",
       "      <td>32.140000</td>\n",
       "      <td>6.395714</td>\n",
       "      <td>13.930000</td>\n",
       "      <td>0.454829</td>\n",
       "      <td>0.174286</td>\n",
       "      <td>0.522143</td>\n",
       "      <td>0.125493</td>\n",
       "      <td>3.693571</td>\n",
       "      <td>7.444286</td>\n",
       "      <td>0.270286</td>\n",
       "      <td>0.271257</td>\n",
       "      <td>3.997143</td>\n",
       "      <td>5.270714</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>1.260000</td>\n",
       "      <td>3.089286</td>\n",
       "      <td>7.363571</td>\n",
       "      <td>3.595000</td>\n",
       "      <td>0.749286</td>\n",
       "      <td>0.527857</td>\n",
       "      <td>1.470714</td>\n",
       "      <td>2.906429</td>\n",
       "      <td>16.952143</td>\n",
       "      <td>2.864286</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>0.407143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.486695</td>\n",
       "      <td>16.835757</td>\n",
       "      <td>3.968530</td>\n",
       "      <td>27.203072</td>\n",
       "      <td>4.061165</td>\n",
       "      <td>313.184389</td>\n",
       "      <td>427.867434</td>\n",
       "      <td>6.424714</td>\n",
       "      <td>2.148276</td>\n",
       "      <td>4.166908</td>\n",
       "      <td>0.055660</td>\n",
       "      <td>0.396454</td>\n",
       "      <td>1.062850</td>\n",
       "      <td>0.152188</td>\n",
       "      <td>3.669066</td>\n",
       "      <td>7.412941</td>\n",
       "      <td>0.250321</td>\n",
       "      <td>0.251175</td>\n",
       "      <td>1.502178</td>\n",
       "      <td>1.939053</td>\n",
       "      <td>0.074647</td>\n",
       "      <td>1.263591</td>\n",
       "      <td>2.937005</td>\n",
       "      <td>4.120666</td>\n",
       "      <td>2.034074</td>\n",
       "      <td>0.705630</td>\n",
       "      <td>0.739830</td>\n",
       "      <td>1.377961</td>\n",
       "      <td>0.577418</td>\n",
       "      <td>5.476838</td>\n",
       "      <td>1.667336</td>\n",
       "      <td>4.166844</td>\n",
       "      <td>1.031144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2003.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1611.000000</td>\n",
       "      <td>1471.000000</td>\n",
       "      <td>45.800000</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>23.800000</td>\n",
       "      <td>0.582000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>0.667000</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>21.300000</td>\n",
       "      <td>0.583000</td>\n",
       "      <td>0.582000</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>30.100000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             From           To         Ht          Wt  Years of Service  \\\n",
       "mean  1968.857143  1980.178571  78.142857  207.792857         11.321429   \n",
       "std     14.486695    16.835757   3.968530   27.203072          4.061165   \n",
       "max   2003.000000  2014.000000  90.000000  325.000000         20.000000   \n",
       "\n",
       "                G           GS         MP         FG        FGA       FG%  \\\n",
       "mean   838.421429   283.185714  32.140000   6.395714  13.930000  0.454829   \n",
       "std    313.184389   427.867434   6.424714   2.148276   4.166908  0.055660   \n",
       "max   1611.000000  1471.000000  45.800000  12.100000  23.800000  0.582000   \n",
       "\n",
       "            3P       3PA       3P%         2P        2PA       2P%      eFG%  \\\n",
       "mean  0.174286  0.522143  0.125493   3.693571   7.444286  0.270286  0.271257   \n",
       "std   0.396454  1.062850  0.152188   3.669066   7.412941  0.250321  0.251175   \n",
       "max   2.300000  5.700000  0.667000  10.800000  21.300000  0.583000  0.582000   \n",
       "\n",
       "            FT        FTA       FT%       ORB        DRB        TRB  \\\n",
       "mean  3.997143   5.270714  0.757664  1.260000   3.089286   7.363571   \n",
       "std   1.502178   1.939053  0.074647  1.263591   2.937005   4.120666   \n",
       "max   7.800000  11.400000  0.904000  5.100000  10.400000  22.900000   \n",
       "\n",
       "            AST       STL       BLK       TOV        PF        PTS     Teams  \\\n",
       "mean   3.595000  0.749286  0.527857  1.470714  2.906429  16.952143  2.864286   \n",
       "std    2.034074  0.705630  0.739830  1.377961  0.577418   5.476838  1.667336   \n",
       "max   11.200000  2.600000  3.100000  4.400000  4.200000  30.100000  9.000000   \n",
       "\n",
       "       AllStars      MVPs  \n",
       "mean   6.300000  0.407143  \n",
       "std    4.166844  1.031144  \n",
       "max   19.000000  6.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(hof_players)\n",
    "hof_players.describe().loc[['mean','std','max']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preliminary analysis on the average of the players' career averagers tells us a few things. The first and the most obvious is that having a HOF selection is afforded to a very select few: only the best. Only 140 out of 4580 total players are currently voted in, or 3.1%. The NBA started inducting in 1959 - 59 years ago - so about 5 players can be expected to be inducted every 2 years. Of course, the amount of people inducted per year has risen and some NBA players from decades ago are retroactively inducted.\n",
    "\n",
    "The second thing we can take away from this just how far out of the pack the averages of the HOF players are. They average close to 7 more years in the league(which makes sense since they also average about 580 more games given that there are 82 games in a season), and close to either double or triple the stats in every other category. \n",
    "\n",
    "The third thing we can see is the MVP count, a HOF averages 0.4 MVPs, while a non-HOF averages 0.003, and while a player doesn't need and MVP to be a HOF, it usually helps. So, who are the players with MVPs that *aren't* currently in the HOF?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kobe Bryant\n",
      "Stephen Curry\n",
      "Tim Duncan\n",
      "Kevin Durant\n",
      "Kevin Garnett\n",
      "LeBron James\n",
      "Dirk Nowitzki\n",
      "Derrick Rose\n",
      "Russell Westbrook\n"
     ]
    }
   ],
   "source": [
    "for player in reg_players[reg_players['MVPs'] > 0].index:\n",
    "    print player"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These players here are either still active or not yet eligible to be nominated, so moving on...\n",
    "\n",
    "HOF players were the best players, but they're still human, and that's evident in some of the stats off the court. Players' height and weight are pretty similar HOF-caliber or not, and they also play for around the same amount of distinct teams. So whether a player is a career journeyman(taking a trip through ~3 teams) or a team's stalwart cornerstone, they're probably about 6'6\", 208lbs and had a career lasting ~11 years.\n",
    "\n",
    "Mimicking basketball-reference, I will run the data through a logistic regression to try and predict future HOF-ers given their current stats. The training data will be all players from 1946, the year the league was formed, to 2015 (a player must be retired for 3 full seasons to be eligible for voting. At the time of me writing this, it is June of 2018, so 3 full seasons since 2015 has already passed.)\n",
    "\n",
    "*NOTE*: Some of the players here, expecially the ones with a lower amount of years of service may have been enshrined due to their coaching prowess, and not their playing abilities. However, these guys still played professional basketball at some point in the NBA, so their statistics will not be removed and will be included in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 3867, Testing: 713\n",
      "Total: 4580\n"
     ]
    }
   ],
   "source": [
    "training_data = pd.concat([reg_players[reg_players['To'] <= 2015],hof_players[hof_players['To'] <= 2015]])\n",
    "training_data.drop_duplicates(inplace=True)\n",
    "training_data_y = np.append(np.zeros(len(reg_players[reg_players['To'] <= 2015])),(np.ones(len(hof_players[hof_players['To'] <= 2015]))))\n",
    "\n",
    "test_data = pd.concat([reg_players[reg_players['To'] > 2015],hof_players[hof_players['To'] > 2015]])\n",
    "test_data.drop_duplicates(inplace=True)\n",
    "\n",
    "print \"Training: %s, Testing: %s\"%(training_data.shape[0],test_data.shape[0])\n",
    "print \"Total: %s\"%(training_data.shape[0]+test_data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3867 training and 713 testing samples are by no means shabby. Most models use 80-20 distribution, but a 85-15 will still yield good results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are currently 33 columns that needs to be considered by the model. This is too many, so I'm going to try to cut it down a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Years of Service', True, 1), ('3PA', True, 1), ('3P%', True, 1), ('2P%', True, 1), ('eFG%', True, 1), ('FT', True, 1), ('FTA', True, 1), ('ORB', True, 1), ('TRB', True, 1), ('AST', True, 1), ('STL', True, 1), ('BLK', True, 1), ('TOV', True, 1), ('Teams', True, 1), ('AllStars', True, 1), ('MVPs', True, 1), ('PF', False, 2), (u'From', False, 3), (u'To', False, 4), ('FGA', False, 5), ('2P', False, 6), ('3P', False, 7), ('FT%', False, 8), ('2PA', False, 9), (u'Wt', False, 10), ('DRB', False, 11), ('FG%', False, 12), ('MP', False, 13), ('FG', False, 14), ('PTS', False, 15), (u'Ht', False, 16), ('G', False, 17), ('GS', False, 18)]\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "rfe = RFE(logreg)\n",
    "rfe = rfe.fit(training_data, training_data_y)\n",
    "print sorted(zip(training_data.columns,rfe.support_, rfe.ranking_),key=lambda x:x[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the Recursive Feature Elimination, the features most likely to affect the outcome of a HOF player is the following:\n",
    "- Years of Service\n",
    "- 3PA\n",
    "- 3P%\n",
    "- 2P%\n",
    "- eFG%\n",
    "- FT\n",
    "- FTA\n",
    "- ORB\n",
    "- TRB\n",
    "- AST\n",
    "- STL\n",
    "- BLK\n",
    "- TOV\n",
    "- Team\n",
    "- AllStars\n",
    "- MVPs\n",
    "\n",
    "This list kind of makes sense, as players that stay in the league longer tend to have a better game. Players also don't-or rather can't-stay around if they're bad either. Shooting percentages are very important and shows how effective a player is. Rebounds-especially offensive rebounds-show grit and hustle, while assists show how much of a team player a player is. Steals and blocks are important too since some players are defensive beasts while being not so gifted on the offensive side. A lower turnover amount means the player is efficient with the possession of the ball. The amount of teams played means either the player was so good or loyal that they weren't traded, or they were good that they were highly sought after. Both explanations are pretty reasonable. Lastly, AllStar selections and MVPs selections are both based off merit. This list generally makes sense, and it shortens down the list from 33 features to about half, at 16. \n",
    "\n",
    "The odd item on the list that I didn't mention above is 3PA, since some players are just _not_ 3pt shooters, and the 3pt line was added later as well. This stat should not be considered as important. FT and FTA are also considered but not FT%, although this might make some sense because free throws are free points and getting to the free throw line can be considered a skill. Clutch free throws are also very important to winning close games.\n",
    "\n",
    "The rest of the features not included isn't suprising since they can either be derived (games played/started is directly related to years played) or they don't matter much since they're close to the average of all players (height and weight). One feature that I'm really shocked to see did not make the list however, is points, since you literally cannot win a game without them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the columns given by RFE for both training and testing dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data_x = training_data[['Years of Service', '3PA', '3P%', '2P%', 'eFG%', 'FT', 'FTA', 'ORB', 'TRB', \\\n",
    "                                  'AST', 'STL', 'BLK', 'TOV', 'Teams', 'AllStars', 'MVPs']]\n",
    "test_data_x = test_data[['Years of Service', '3PA', '3P%', '2P%', 'eFG%', 'FT', 'FTA', 'ORB', 'TRB', \\\n",
    "                                  'AST', 'STL', 'BLK', 'TOV', 'Teams', 'AllStars', 'MVPs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(training_data_x, training_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "LaMarcus Aldridge\n",
      "Carmelo Anthony\n",
      "Chris Bosh\n",
      "Kobe Bryant\n",
      "Stephen Curry\n",
      "Tim Duncan\n",
      "Kevin Durant\n",
      "Kevin Garnett\n",
      "Pau Gasol\n",
      "Blake Griffin\n",
      "James Harden\n",
      "Dwight Howard\n",
      "LeBron James\n",
      "Dirk Nowitzki\n",
      "Tony Parker\n",
      "Chris Paul\n",
      "Paul Pierce\n",
      "Amar'e Stoudemire\n",
      "Dwyane Wade\n",
      "John Wall\n",
      "Russell Westbrook\n"
     ]
    }
   ],
   "source": [
    "test_data_x[\"HOF?\"] = logreg.predict(test_data_x)\n",
    "print len(test_data_x[test_data_x[\"HOF?\"] == 1])\n",
    "for player in test_data_x[test_data_x[\"HOF?\"] == 1].index.tolist():\n",
    "    print player"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This list seems somewhat short, with only 21 of the possible 713 eligible players having a 100% chance. (100% because the predict function only returns a binary value.) To add to that, 21/713 is 2.9%, which isn't that far off from the current HOF percentage of 3.1%. All of these players are also known for high levels of play and have either won MVPs and championships were close to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset for the probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player\n",
      "LeBron James         0.999999\n",
      "Tim Duncan           0.999994\n",
      "Kobe Bryant          0.999991\n",
      "Kevin Garnett        0.999856\n",
      "Dirk Nowitzki        0.999740\n",
      "Dwyane Wade          0.994220\n",
      "Russell Westbrook    0.990159\n",
      "Kevin Durant         0.986226\n",
      "Chris Bosh           0.980685\n",
      "Paul Pierce          0.960214\n",
      "Carmelo Anthony      0.955126\n",
      "Name: HOF?, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "test_data_x = test_data[['Years of Service', '3PA', '3P%', '2P%', 'eFG%', 'FT', 'FTA', 'ORB', 'TRB', \\\n",
    "                                  'AST', 'STL', 'BLK', 'TOV', 'Teams', 'AllStars', 'MVPs']]\n",
    "\n",
    "test_data_x[\"HOF?\"] = [x[1] for x in logreg.predict_proba(test_data_x)]\n",
    "print test_data_x[test_data_x[\"HOF?\"] > 0.95][\"HOF?\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, this model has been pretty consistent in the results, and matches wih the basketballreference model results well. Some of the player's probability rankings are not the same, but the results are similar. There are outliers, however, Vince Carter Chris Paul, and James Harden  does not appear in my model's top 10, but they do on the one for basketballreference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player\n",
      "LeBron James         0.999999\n",
      "Tim Duncan           0.999994\n",
      "Kobe Bryant          0.999991\n",
      "Kevin Garnett        0.999856\n",
      "Dirk Nowitzki        0.999740\n",
      "Dwyane Wade          0.994220\n",
      "Russell Westbrook    0.990159\n",
      "Kevin Durant         0.986226\n",
      "Chris Bosh           0.980685\n",
      "Paul Pierce          0.960214\n",
      "Carmelo Anthony      0.955126\n",
      "Stephen Curry        0.933087\n",
      "Chris Paul           0.903754\n",
      "Dwight Howard        0.886409\n",
      "Tony Parker          0.877733\n",
      "John Wall            0.770405\n",
      "Pau Gasol            0.763726\n",
      "James Harden         0.720776\n",
      "Blake Griffin        0.598244\n",
      "LaMarcus Aldridge    0.577846\n",
      "Amar'e Stoudemire    0.570620\n",
      "Name: HOF?, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print test_data_x[test_data_x[\"HOF?\"] >= 0.5][\"HOF?\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lowering the threshold to 0.5, which is were the predict function will round up to the binary 1, we get back the list of 21 players. Vince Carter is still not on the list, but the other 2 makes their appearances. Another oddity that I've noticed is that at rank 21, Amare'e Stoudemire has a 57% chance of being a HOF, while for basketballreference, LeMarcus Aldridge only has a 21% chance. Player name aside, it does seem that my model has a higher average % chance of players making it to the HOF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's investigate Vince Carter's HOF chances using my model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.485976892722\n"
     ]
    }
   ],
   "source": [
    "print test_data_x.ix[\"Vince Carter\"][\"HOF?\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like he just barely missed the 0.5 mark used for rounding, let's see if here are other players who barely missed as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player\n",
      "Vince Carter        0.485977\n",
      "DeMarcus Cousins    0.479510\n",
      "Name: HOF?, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print test_data_x[(test_data_x[\"HOF?\"] >= 0.45) & (test_data_x[\"HOF?\"] < 0.5)][\"HOF?\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cousins also barely missed the cut, this model has him at 48%, while basektballreference has him at around 1.3%. Only time will tell now...\n",
    "\n",
    "Before I wrap this up, I'm going to tweak the model with what I think are the best metrics for evaluating a player's HOF-worthiness. This includes taking out the 3PA and putting in PTs. I'll also throw in FG%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player\n",
      "LeBron James         0.999999\n",
      "Tim Duncan           0.999994\n",
      "Kobe Bryant          0.999989\n",
      "Kevin Garnett        0.999846\n",
      "Dirk Nowitzki        0.999727\n",
      "Dwyane Wade          0.993786\n",
      "Russell Westbrook    0.989357\n",
      "Kevin Durant         0.986331\n",
      "Chris Bosh           0.979359\n",
      "Paul Pierce          0.955146\n",
      "Carmelo Anthony      0.955081\n",
      "Name: HOF?, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_data_x = training_data[['Years of Service', '3PA', 'PTS', '3P%', '2P%', 'eFG%', 'FT', 'FTA', 'ORB', 'TRB', \\\n",
    "                                  'AST', 'STL', 'BLK', 'TOV', 'Teams', 'AllStars', 'MVPs']]\n",
    "test_data_x = test_data[['Years of Service', '3PA', 'PTS', '3P%', '2P%', 'eFG%', 'FT', 'FTA', 'ORB', 'TRB', \\\n",
    "                                  'AST', 'STL', 'BLK', 'TOV', 'Teams', 'AllStars', 'MVPs']]\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(training_data_x, training_data_y)\n",
    "\n",
    "test_data_x[\"HOF?\"] = [x[1] for x in logreg.predict_proba(test_data_x)]\n",
    "print test_data_x[test_data_x[\"HOF?\"] > 0.95][\"HOF?\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like the RFE was correct, since the results of those with 95%+ are the same."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
